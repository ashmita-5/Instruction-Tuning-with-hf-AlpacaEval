{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5896b1a6-8ed4-4484-96e5-50d0ac10b73a",
   "metadata": {},
   "source": [
    "# [Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "\n",
    "Supervised fine-tuning (or SFT for short) is a crucial step in RLHF. In TRL we provide an easy-to-use API to create your SFT models and train them with few lines of code on your dataset.\n",
    "\n",
    "[Python Script](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f636b5-91b3-4a45-a6cf-334425eac4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft==0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (23.2)\n",
      "Requirement already satisfied: psutil in /Users/ashmitaphuyal/Library/Python/3.11/lib/python/site-packages (from peft==0.7.1) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (2.2.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (4.39.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (0.25.0)\n",
      "Requirement already satisfied: safetensors in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from peft==0.7.1) (0.20.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.7.1) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers->peft==0.7.1) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers->peft==0.7.1) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft==0.7.1) (1.3.0)\n",
      "Requirement already satisfied: trl==0.7.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.7.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trl==0.7.4) (2.2.2)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trl==0.7.4) (4.39.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trl==0.7.4) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trl==0.7.4) (0.25.0)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trl==0.7.4) (2.18.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trl==0.7.4) (0.7.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.4.0->trl==0.7.4) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (0.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers>=4.18.0->trl==0.7.4) (4.66.2)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tyro>=0.5.11->trl==0.7.4) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tyro>=0.5.11->trl==0.7.4) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tyro>=0.5.11->trl==0.7.4) (1.7.1)\n",
      "Requirement already satisfied: psutil in /Users/ashmitaphuyal/Library/Python/3.11/lib/python/site-packages (from accelerate->trl==0.7.4) (5.9.5)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets->trl==0.7.4) (12.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets->trl==0.7.4) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets->trl==0.7.4) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets->trl==0.7.4) (2.1.0)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets->trl==0.7.4) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets->trl==0.7.4) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets->trl==0.7.4) (3.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->datasets->trl==0.7.4) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ashmitaphuyal/Library/Python/3.11/lib/python/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl==0.7.4) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ashmitaphuyal/Library/Python/3.11/lib/python/site-packages (from pandas->datasets->trl==0.7.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets->trl==0.7.4) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets->trl==0.7.4) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl==0.7.4) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashmitaphuyal/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.4) (1.16.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer==4.36.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer==4.36.2\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install peft==0.7.1\n",
    "!pip3 install trl==0.7.4\n",
    "!pip3 install transformer==4.36.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fd24274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.39.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7263f867",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'top_k_top_p_filtering' from 'transformers' (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtrl\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trl\u001b[39m.\u001b[39m__version__\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/trl/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.7.4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m set_seed\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39menvironment\u001b[39;00m \u001b[39mimport\u001b[39;00m TextEnvironment, TextHistory\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextras\u001b[39;00m \u001b[39mimport\u001b[39;00m BestOfNSampler\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/trl/core.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrnn\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequence\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m top_k_top_p_filtering\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_xpu_available\n\u001b[1;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'top_k_top_p_filtering' from 'transformers' (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import trl\n",
    "trl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed1948-2b9b-4324-ba26-36b6c95fdbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "#os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "#os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3fdeadb-5929-4c60-95cb-17c465902fd6",
   "metadata": {},
   "source": [
    "## Basic SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f87cd-e167-416a-912c-db3367cafd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba085de754ca40bca7ad8266038de089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output', 'input'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset_path = 'alpaca_data.json'\n",
    "# Create a Dataset object\n",
    "dataset = Dataset.from_json(dataset_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b8a29-e81f-40a8-8d00-ee2f2b8bec54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Give three tips for staying healthy.',\n",
       " 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.',\n",
       " 'input': ''}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32e505-24a5-4cd7-9f6b-25c1105ca996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af52e944e514e3ab0b52f24f8900498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee821bc457e44cb08e7443e2cf1b73b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1a8172212e4ca6a78fbda056f28cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38f9789c2a14b6a957044430921b562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0beedc1c824163a4ff94badaf0704c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630b8164f7b94029ae8a2564d7912c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3628a3c9fb06438fba24c162847b11bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the model & Tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    device_map = 'auto'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path)\n",
    "\n",
    "# Make sure to pass a correct value for max_seq_length as the default value will be set to min(tokenizer.model_max_length, 1024).\n",
    "max_seq_length = min(tokenizer.model_max_length, 1024)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610979a-eaa1-4773-9912-92c125c8dc2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'top_k_top_p_filtering' from 'transformers' (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Step 3: Define the Trainer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainingArguments\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrl\u001b[39;00m \u001b[39mimport\u001b[39;00m SFTTrainer\n\u001b[1;32m      4\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      5\u001b[0m     output_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtmp_trainer\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m#default = 'tmp_trainer'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     num_train_epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m#default = 3\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m trainer \u001b[39m=\u001b[39m SFTTrainer(\n\u001b[1;32m     10\u001b[0m     model \u001b[39m=\u001b[39m model,\n\u001b[1;32m     11\u001b[0m     args \u001b[39m=\u001b[39m training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     max_seq_length \u001b[39m=\u001b[39m max_seq_length,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/trl/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.7.4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m set_seed\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39menvironment\u001b[39;00m \u001b[39mimport\u001b[39;00m TextEnvironment, TextHistory\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextras\u001b[39;00m \u001b[39mimport\u001b[39;00m BestOfNSampler\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/trl/core.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrnn\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequence\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m top_k_top_p_filtering\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_xpu_available\n\u001b[1;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'top_k_top_p_filtering' from 'transformers' (/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Step 3: Define the Trainer\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'tmp_trainer', #default = 'tmp_trainer'\n",
    "    num_train_epochs=5, #default = 3\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = dataset.select(range(1000)),\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80b08a-39c9-4823-961b-b768b9054444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 02:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.580700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=625, training_loss=3.558915576171875, metrics={'train_runtime': 163.9405, 'train_samples_per_second': 30.499, 'train_steps_per_second': 3.812, 'total_flos': 837709216874496.0, 'train_loss': 3.558915576171875, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16f67f1-c0e4-40e9-b192-4d1a9cfbfb17",
   "metadata": {},
   "source": [
    "## Instruction-Tuning\n",
    "Train on completions only\n",
    "- Use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only.\n",
    "- Note that this works only in the case when packing=False.\n",
    "- To instantiate that collator for instruction data, pass a response template and the tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ea5ec-482c-4520-bd97-3ccc1f2961f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 20022\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ee677-ddc8-4a81-9d86-9219de3d84f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Design an algorithm for finding the nth node from the tail of a linked list.',\n",
       " 'input': '',\n",
       " 'output': '\"\"\"\\ndef nthFromLast(head, n): \\n    # Initialize slow and fast pointers \\n    slow  = head \\n    fast = head \\n  \\n    # Move fast pointer n-1 times \\n    while (n > 0): \\n        if (fast == None): \\n            return None\\n  \\n        fast = fast.next\\n        n = n - 1\\n  \\n    # Move both slow and fast pointer together \\n    while (fast.next != None): \\n        slow = slow.next\\n        fast = fast.next\\n  \\n    return slow\\n\"\"\"'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69100196-d9d8-4791-9e11-6e93f1bd7550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todsavadt/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/todsavadt/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/todsavadt/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load the model & Tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, device_map = 'auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d350a2-002b-40e2-8c10-9afea5923cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['### Question: Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.\\n ### Answer: def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x',\n",
       " \"### Question: Generate a unique 8 character string that contains a lowercase letter, an uppercase letter, a numerical digit, and a special character. Write corresponding code in Python.\\n ### Answer: import string\\nimport random\\n\\ndef random_password_string():\\n    characters = string.ascii_letters + string.digits + string.punctuation\\n    password = ''.join(random.sample(characters, 8))\\n    return password\\n\\nif __name__ == '__main__':\\n    print(random_password_string())\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "#check instruction-prompt\n",
    "formatting_prompts_func(dataset[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e5c61-8397-4fd6-bcc2-b5c8c929b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todsavadt/.local/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataCollatorForCompletionOnlyLM(tokenizer=GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "response_template = \" ### Answer:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28385087-8eb8-4b83-a7dd-1313bf591b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todsavadt/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "Loading cached processed dataset at /home/todsavadt/.cache/huggingface/datasets/lucasmccabe-lmi___parquet/lucasmccabe-lmi--CodeAlpaca-20k-b92d1194a2c963a0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-40d1763a83a210c6.arrow\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 02:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=1.802888671875, metrics={'train_runtime': 165.0694, 'train_samples_per_second': 18.174, 'train_steps_per_second': 2.272, 'total_flos': 211711609405440.0, 'train_loss': 1.802888671875, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Define the Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset.select(range(1000)),\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "trainer.train() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eacf03b-d3f7-4daa-9644-38b3c63abe80",
   "metadata": {},
   "source": [
    "### Standard-Alpaca : Format your input prompts\n",
    "For instruction fine-tuning, it is quite common to have two columns inside the dataset: one for the prompt & the other for the response.\n",
    "\n",
    "This allows people to format examples like Stanford-Alpaca did as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add62276-69ea-48ce-bd11-58fb49d09d46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "test = '''\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{response}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d770c-7d3c-497b-bf87-56510676bd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa74025f51474091bd338e74dd1f2f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/199 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188d110c1725440082863a4b7162e6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/461k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7506132ec0ae4bfbbdb303d2406ddf8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'completion'],\n",
       "        num_rows: 327\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceH4/instruction-dataset\")\n",
    "dataset = dataset.remove_columns(\"meta\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26e774-a2ff-475a-927a-a5cfe7f413ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nArianna has 12 chocolates more than Danny. Danny has 6 chocolates more than Robbie. Arianna has twice as many chocolates as Robbie has. How many chocolates does Danny have?\\n\\n### Response:\\nDenote the number of chocolates each person has by the letter of their first name. We know that\\nA = D + 12\\nD = R + 6\\nA = 2 * R\\n\\nThus, A = (R + 6) + 12 = R + 18\\nSince also A = 2 * R, this means 2 * R = R + 18\\nHence R = 18\\nHence D = 18 + 6 = 24'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_instruction(sample):\n",
    "\treturn f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{sample['prompt']}\n",
    "\n",
    "### Response:\n",
    "{sample['completion']}\n",
    "\"\"\".strip()\n",
    "\n",
    "format_instruction(dataset['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0e377-4257-497e-9a82-2562734e95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", device_map = 'auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e9c92-3491-44c8-bfa1-f289406585ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123/123 01:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=123, training_loss=3.2161634491711126, metrics={'train_runtime': 61.2649, 'train_samples_per_second': 16.012, 'train_steps_per_second': 2.008, 'total_flos': 87600245981184.0, 'train_loss': 3.2161634491711126, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    formatting_func=format_instruction,\n",
    ")\n",
    "\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a4157-e6d1-4e3e-8c4a-d2d56c57887c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
